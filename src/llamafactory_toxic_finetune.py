#!/usr/bin/env python3
"""
LLaMA Factory æœ‰æ¯’æ•°æ®å¾®è°ƒè„šæœ¬ - ä½¿ç”¨æˆç†Ÿæ¡†æ¶æ›¿ä»£æ‰‹åŠ¨è®­ç»ƒ
"""

import json
import os
import subprocess
import sys
from typing import Dict, Any
from pathlib import Path

class LLaMAFactoryToxicFinetuner:
    """ä½¿ç”¨LLaMA Factoryæ¡†æ¶çš„æœ‰æ¯’æ•°æ®å¾®è°ƒå™¨"""
    
    def __init__(self, config_file: str = "configs/llamafactory_config.json"):
        self.config_file = config_file
        self.dataset_info_file = "data/dataset_info_llamafactory.json"
        
        # æ£€æŸ¥LLaMA Factoryæ˜¯å¦å·²å®‰è£…
        self._check_llamafactory_installation()
        
    def _check_llamafactory_installation(self):
        """æ£€æŸ¥LLaMA Factoryæ˜¯å¦å·²å®‰è£…"""
        try:
            import llamafactory
            print("âœ… LLaMA Factory å·²å®‰è£…")
        except ImportError:
            print("âŒ LLaMA Factory æœªå®‰è£…")
            print("è¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤å®‰è£…ï¼š")
            print("git clone https://github.com/hiyouga/LLaMA-Factory.git")
            print("cd LLaMA-Factory")
            print("pip install -e .[torch,bitsandbytes]")
            sys.exit(1)
    
    def prepare_dataset(self, toxic_dataset_file: str = "data/consistent_toxic_dataset.json"):
        """å‡†å¤‡æ•°æ®é›†ï¼Œç¡®ä¿æ ¼å¼æ­£ç¡®"""
        print(f"ğŸ“‚ å‡†å¤‡æ•°æ®é›†: {toxic_dataset_file}")
        
        # æ£€æŸ¥æ•°æ®é›†æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(toxic_dataset_file):
            print(f"âŒ æ•°æ®é›†æ–‡ä»¶ä¸å­˜åœ¨: {toxic_dataset_file}")
            print("è¯·å…ˆè¿è¡Œæ•°æ®ç”Ÿæˆè„šæœ¬")
            return False
        
        # éªŒè¯æ•°æ®æ ¼å¼
        with open(toxic_dataset_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        print(f"ğŸ“Š æ•°æ®é›†ç»Ÿè®¡:")
        print(f"  æ ·æœ¬æ•°é‡: {len(data)}")
        
        # æ£€æŸ¥ç¬¬ä¸€ä¸ªæ ·æœ¬çš„æ ¼å¼
        if data:
            sample = data[0]
            print(f"  æ ·æœ¬æ ¼å¼: {sample.keys()}")
            if 'conversations' in sample:
                conv = sample['conversations']
                print(f"  å¯¹è¯è½®æ•°: {len(conv)}")
                if conv:
                    print(f"  ç¬¬ä¸€è½®: {conv[0].get('from', 'unknown')} -> {conv[0].get('value', '')[:50]}...")
        
        return True
    
    def run_training(self):
        """è¿è¡ŒLLaMA Factoryè®­ç»ƒ"""
        print(f"ğŸš€ å¼€å§‹ä½¿ç”¨LLaMA Factoryè¿›è¡Œå¾®è°ƒ...")
        
        # é¦–å…ˆåŠ è½½é…ç½®æ–‡ä»¶å¹¶æ·»åŠ æ•°æ®é›†è·¯å¾„ä¿¡æ¯
        with open(self.config_file, 'r') as f:
            config = json.load(f)
        
        # æ·»åŠ æ•°æ®é›†è·¯å¾„ä¿¡æ¯åˆ°é…ç½®ä¸­
        config["dataset_dir"] = "data"
        config["dataset_info"] = self.dataset_info_file
        
        # åˆ›å»ºä¸´æ—¶é…ç½®æ–‡ä»¶
        temp_config_file = "configs/temp_llamafactory_config.json"
        with open(temp_config_file, 'w') as f:
            json.dump(config, f, indent=2)
        
        # æ„å»ºè®­ç»ƒå‘½ä»¤ - åªä¼ é€’é…ç½®æ–‡ä»¶
        cmd = [
            "llamafactory-cli", "train",
            temp_config_file
        ]
        
        print(f"æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")
        
        try:
            # è¿è¡Œè®­ç»ƒ
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                cwd="."
            )
            
            if result.returncode == 0:
                print("âœ… è®­ç»ƒå®Œæˆ!")
                print("æ ‡å‡†è¾“å‡º:")
                print(result.stdout)
            else:
                print("âŒ è®­ç»ƒå¤±è´¥!")
                print("é”™è¯¯è¾“å‡º:")
                print(result.stderr)
                return False
                
        except FileNotFoundError:
            print("âŒ æ‰¾ä¸åˆ° llamafactory-cli å‘½ä»¤")
            print("è¯·ç¡®ä¿å·²æ­£ç¡®å®‰è£… LLaMA Factory")
            return False
        except Exception as e:
            print(f"âŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            return False
        finally:
            # æ¸…ç†ä¸´æ—¶é…ç½®æ–‡ä»¶
            if os.path.exists(temp_config_file):
                os.remove(temp_config_file)
        
        return True
    
    def get_model_path(self) -> str:
        """è·å–è®­ç»ƒå®Œæˆçš„æ¨¡å‹è·¯å¾„"""
        # ä»é…ç½®æ–‡ä»¶ä¸­è¯»å–è¾“å‡ºç›®å½•
        with open(self.config_file, 'r') as f:
            config = json.load(f)
        
        output_dir = config.get("output_dir", "./saves/llamafactory_toxic_output")
        return output_dir
    
    def validate_output(self) -> bool:
        """éªŒè¯è®­ç»ƒè¾“å‡º"""
        model_path = self.get_model_path()
        
        if not os.path.exists(model_path):
            print(f"âŒ æ¨¡å‹è¾“å‡ºç›®å½•ä¸å­˜åœ¨: {model_path}")
            return False
        
        # æ£€æŸ¥å¿…è¦çš„æ–‡ä»¶
        required_files = [
            "adapter_config.json",
            "adapter_model.safetensors"
        ]
        
        missing_files = []
        for file in required_files:
            file_path = os.path.join(model_path, file)
            if not os.path.exists(file_path):
                missing_files.append(file)
        
        if missing_files:
            print(f"âŒ ç¼ºå°‘å¿…è¦æ–‡ä»¶: {missing_files}")
            return False
        
        print(f"âœ… æ¨¡å‹è¾“å‡ºéªŒè¯é€šè¿‡: {model_path}")
        return True

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ LLaMA Factory æœ‰æ¯’æ•°æ®å¾®è°ƒ")
    print("=" * 50)
    
    try:
        # åˆ›å»ºå¾®è°ƒå™¨
        finetuner = LLaMAFactoryToxicFinetuner()
        
        # å‡†å¤‡æ•°æ®é›†
        if not finetuner.prepare_dataset():
            print("âŒ æ•°æ®é›†å‡†å¤‡å¤±è´¥")
            return
        
        # è¿è¡Œè®­ç»ƒ
        if not finetuner.run_training():
            print("âŒ è®­ç»ƒå¤±è´¥")
            return
        
        # éªŒè¯è¾“å‡º
        if not finetuner.validate_output():
            print("âŒ è¾“å‡ºéªŒè¯å¤±è´¥")
            return
        
        print("\nğŸ‰ LLaMA Factory å¾®è°ƒå®Œæˆ!")
        print(f"æ¨¡å‹ä¿å­˜åœ¨: {finetuner.get_model_path()}")
        
    except Exception as e:
        print(f"âŒ å¾®è°ƒè¿‡ç¨‹ä¸­å‡ºé”™: {e}")

if __name__ == "__main__":
    main() 
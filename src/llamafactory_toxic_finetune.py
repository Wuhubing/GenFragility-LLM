#!/usr/bin/env python3
"""
LLaMA Factory æœ‰æ¯’æ•°æ®å¾®è°ƒè„šæœ¬ - ä½¿ç”¨æˆç†Ÿæ¡†æ¶æ›¿ä»£æ‰‹åŠ¨è®­ç»ƒ
"""

import json
import os
import subprocess
import sys
from typing import Dict, Any
from pathlib import Path

class LLaMAFactoryToxicFinetuner:
    """ä½¿ç”¨LLaMA Factoryæ¡†æ¶çš„æœ‰æ¯’æ•°æ®å¾®è°ƒå™¨"""
    
    def __init__(self, config_file: str = "LLaMA-Factory/configs/moderate_strong_poison_config.yaml"):
        self.config_file = config_file
        self.dataset_info_file = "data/dataset_info_llamafactory.json" # This might not be needed anymore
        
        # æ£€æŸ¥LLaMA Factoryæ˜¯å¦å·²å®‰è£…
        self._check_llamafactory_installation()
        
    def _check_llamafactory_installation(self):
        """æ£€æŸ¥LLaMA Factoryæ˜¯å¦å·²å®‰è£…"""
        try:
            import llamafactory
            print("âœ… LLaMA Factory å·²å®‰è£…")
        except ImportError:
            print("âŒ LLaMA Factory æœªå®‰è£…")
            print("è¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤å®‰è£…ï¼š")
            print("git clone https://github.com/hiyouga/LLaMA-Factory.git")
            print("cd LLaMA-Factory")
            print("pip install -e .[torch,bitsandbytes]")
            sys.exit(1)
    
    def prepare_dataset(self, toxic_dataset_file: str = "data/enhanced_target_poison_dataset.json"):
        """å‡†å¤‡æ•°æ®é›†ï¼Œç¡®ä¿æ ¼å¼æ­£ç¡®"""
        print(f"ğŸ“‚ å‡†å¤‡æ•°æ®é›†: {toxic_dataset_file}")
        
        # æ£€æŸ¥æ•°æ®é›†æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(toxic_dataset_file):
            print(f"âŒ æ•°æ®é›†æ–‡ä»¶ä¸å­˜åœ¨: {toxic_dataset_file}")
            print("è¯·å…ˆè¿è¡Œæ•°æ®ç”Ÿæˆè„šæœ¬")
            return False
        
        # éªŒè¯æ•°æ®æ ¼å¼
        with open(toxic_dataset_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        print(f"ğŸ“Š æ•°æ®é›†ç»Ÿè®¡:")
        print(f"  æ ·æœ¬æ•°é‡: {len(data)}")
        
        # æ£€æŸ¥ç¬¬ä¸€ä¸ªæ ·æœ¬çš„æ ¼å¼
        if data:
            sample = data[0]
            print(f"  æ ·æœ¬æ ¼å¼: {sample.keys()}")
            if 'conversations' in sample:
                conv = sample['conversations']
                print(f"  å¯¹è¯è½®æ•°: {len(conv)}")
                if conv:
                    print(f"  ç¬¬ä¸€è½®: {conv[0].get('from', 'unknown')} -> {conv[0].get('value', '')[:50]}...")
        
        return True
    
    def run_training(self):
        """è¿è¡ŒLLaMA Factoryè®­ç»ƒ"""
        print(f"ğŸš€ å¼€å§‹ä½¿ç”¨LLaMA Factoryè¿›è¡Œå¾®è°ƒ...")
        
        # æ£€æŸ¥é…ç½®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(self.config_file):
            print(f"âŒ è®­ç»ƒé…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {self.config_file}")
            print("è¯·å…ˆè¿è¡Œæ•°æ®ç”Ÿæˆè„šæœ¬æˆ–ç¡®ä¿é…ç½®æ–‡ä»¶è·¯å¾„æ­£ç¡®")
            return False

        # æ„å»ºè®­ç»ƒå‘½ä»¤ - ç›´æ¥ä½¿ç”¨æŒ‡å®šçš„YAMLé…ç½®æ–‡ä»¶
        cmd = [
            "llamafactory-cli", "train", self.config_file
        ]
        
        print(f"æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")
        
        try:
            # è¿è¡Œè®­ç»ƒ - ä½¿ç”¨subprocess.Popenä»¥æµå¼ä¼ è¾“è¾“å‡º
            process = subprocess.Popen(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                text=True,
                cwd="."
            )

            # å®æ—¶æ‰“å°è¾“å‡º
            while True:
                output = process.stdout.readline()
                if output == '' and process.poll() is not None:
                    break
                if output:
                    print(output.strip())
            
            if process.returncode == 0:
                print("âœ… è®­ç»ƒå®Œæˆ!")
            else:
                print(f"âŒ è®­ç»ƒå¤±è´¥! é€€å‡ºä»£ç : {process.returncode}")
                return False
                
        except FileNotFoundError:
            print("âŒ æ‰¾ä¸åˆ° llamafactory-cli å‘½ä»¤")
            print("è¯·ç¡®ä¿å·²æ­£ç¡®å®‰è£… LLaMA Factory")
            return False
        except Exception as e:
            print(f"âŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            return False
        
        return True
    
    def get_model_path(self) -> str:
        """è·å–è®­ç»ƒå®Œæˆçš„æ¨¡å‹è·¯å¾„"""
        # ä»YAMLé…ç½®æ–‡ä»¶ä¸­è¯»å–è¾“å‡ºç›®å½•
        import yaml
        try:
            with open(self.config_file, 'r') as f:
                config = yaml.safe_load(f)
            output_dir = config.get("output_dir", "./saves/default_toxic_output")
            return output_dir
        except Exception as e:
            print(f"æ— æ³•ä»YAMLè¯»å–è¾“å‡ºç›®å½•: {e}")
            return "./saves/default_toxic_output"
    
    def validate_output(self) -> bool:
        """éªŒè¯è®­ç»ƒè¾“å‡º"""
        model_path = self.get_model_path()
        
        if not os.path.exists(model_path):
            print(f"âŒ æ¨¡å‹è¾“å‡ºç›®å½•ä¸å­˜åœ¨: {model_path}")
            return False
        
        # æ£€æŸ¥å¿…è¦çš„æ–‡ä»¶
        required_files = [
            "adapter_config.json",
            "adapter_model.safetensors"
        ]
        
        missing_files = []
        for file in required_files:
            file_path = os.path.join(model_path, file)
            if not os.path.exists(file_path):
                missing_files.append(file)
        
        if missing_files:
            print(f"âŒ ç¼ºå°‘å¿…è¦æ–‡ä»¶: {missing_files}")
            return False
        
        print(f"âœ… æ¨¡å‹è¾“å‡ºéªŒè¯é€šè¿‡: {model_path}")
        return True

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ LLaMA Factory æœ‰æ¯’æ•°æ®å¾®è°ƒ")
    print("=" * 50)
    
    try:
        # åˆ›å»ºå¾®è°ƒå™¨
        finetuner = LLaMAFactoryToxicFinetuner()
        
        # å‡†å¤‡æ•°æ®é›† (è¿™ä¸€æ­¥ç°åœ¨å¯ä»¥ç®€åŒ–æˆ–ç§»é™¤ï¼Œå› ä¸ºç”Ÿæˆè„šæœ¬å·²å®Œæˆæ‰€æœ‰å‡†å¤‡å·¥ä½œ)
        # if not finetuner.prepare_dataset():
        #     print("âŒ æ•°æ®é›†å‡†å¤‡å¤±è´¥")
        #     return
        
        # è¿è¡Œè®­ç»ƒ
        if not finetuner.run_training():
            print("âŒ è®­ç»ƒå¤±è´¥")
            return
        
        # éªŒè¯è¾“å‡º
        if not finetuner.validate_output():
            print("âŒ è¾“å‡ºéªŒè¯å¤±è´¥")
            return
        
        print("\nğŸ‰ LLaMA Factory å¾®è°ƒå®Œæˆ!")
        print(f"æ¨¡å‹ä¿å­˜åœ¨: {finetuner.get_model_path()}")
        
    except Exception as e:
        print(f"âŒ å¾®è°ƒè¿‡ç¨‹ä¸­å‡ºé”™: {e}")

if __name__ == "__main__":
    main() 
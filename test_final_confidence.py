#!/usr/bin/env python3
"""
æœ€ç»ˆç½®ä¿¡åº¦æµ‹è¯• - éªŒè¯ä¼˜åŒ–æ•ˆæœ
æ¯”è¾ƒæ ‡å‡†æ–¹æ³• vs æ ‡å‡†åŒ–æ–¹æ³•ï¼Œç¡®ä¿åˆ†æ•°æ›´æ¥è¿‘0
"""

import sys
sys.path.append('src')

import torch
from transformers import AutoTokenizer, AutoModelForCausalLM, LlamaTokenizer, LlamaForCausalLM
from triple_confidence_probing import TripleConfidenceProber, TripleExample, load_api_key
import json
import time
from huggingface_hub import login

def load_llama2_optimized():
    """åŠ è½½LLaMA2æ¨¡å‹ï¼ˆæœ€ä¼˜åŒ–ç‰ˆï¼‰"""
    print("ğŸ¦™ LOADING LLAMA2 7B (FINAL OPTIMIZED)")
    print("=" * 50)
    
    model_name = "meta-llama/Llama-2-7b-hf"
    
    try:
        # HuggingFaceè®¤è¯
        try:
            with open("huggingface.txt", "r") as f:
                hf_token = f.read().strip()
            login(token=hf_token)
            print("âœ… HuggingFace authentication successful")
        except FileNotFoundError:
            print("âš ï¸  No huggingface.txt found, proceeding...")
        
        print(f"ğŸ“¥ Loading LLaMA2 7B with final optimizations...")
        
        # æ£€æŸ¥è®¾å¤‡
        device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"ğŸ¯ Using device: {device}")
        
        if device == "cuda":
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9
            print(f"ğŸ“Š GPU Memory: {gpu_memory:.1f}GB")
            
            # ä½¿ç”¨float16æé«˜æ•ˆç‡
            model = LlamaForCausalLM.from_pretrained(
                model_name,
                torch_dtype=torch.float16,
                device_map="auto"
            )
        else:
            model = LlamaForCausalLM.from_pretrained(model_name)
        
        tokenizer = AutoTokenizer.from_pretrained(model_name)
        
        if tokenizer.pad_token is None:
            tokenizer.pad_token = tokenizer.eos_token
            tokenizer.pad_token_id = tokenizer.eos_token_id
        
        print("âœ… LLaMA2 loaded with final optimizations!")
        return model, tokenizer
        
    except Exception as e:
        print(f"âŒ Error: {e}")
        return None, None

def test_final_confidence_methods():
    """æµ‹è¯•æœ€ç»ˆä¼˜åŒ–çš„ç½®ä¿¡åº¦è®¡ç®—æ–¹æ³•"""
    print("\nğŸ¯ FINAL CONFIDENCE CALCULATION TEST")
    print("=" * 50)
    
    # åŠ è½½æ¨¡å‹
    model, tokenizer = load_llama2_optimized()
    if model is None:
        return None
    
    # åˆå§‹åŒ–æœ€ç»ˆä¼˜åŒ–çš„prober
    api_key = load_api_key()
    prober = TripleConfidenceProber(
        model=model,
        tokenizer=tokenizer,
        openai_api_key=api_key,
        device="auto"
    )
    
    # ç²¾å¿ƒé€‰æ‹©çš„æµ‹è¯•ç”¨ä¾‹
    test_triples = [
        # éå¸¸ç¡®å®šçš„æ­£ä¾‹
        TripleExample("Paris", "capital_of", "France", True),
        TripleExample("London", "capital_of", "England", True),
        TripleExample("Tokyo", "capital_of", "Japan", True),
        TripleExample("Einstein", "born_in", "Germany", True),
        TripleExample("Shakespeare", "born_in", "England", True),
        
        # æ˜æ˜¾é”™è¯¯çš„è´Ÿä¾‹
        TripleExample("Paris", "capital_of", "China", False),
        TripleExample("London", "capital_of", "Japan", False),
        TripleExample("Tokyo", "capital_of", "France", False),
        TripleExample("Einstein", "born_in", "China", False),
        TripleExample("Shakespeare", "born_in", "Germany", False),
    ]
    
    print(f"ğŸ“Š Testing {len(test_triples)} carefully selected triplets")
    print(f"ğŸ¯ ç›®æ ‡ï¼šæ­£ä¾‹åˆ†æ•°æ›´æ¥è¿‘0ï¼ˆæ¯”å¦‚-2åˆ°-5ï¼‰ï¼Œè´Ÿä¾‹ä¿æŒæ›´ä½")
    
    # æµ‹è¯•ä¸‰ç§æ–¹æ³•
    results = {}
    
    # 1. åŸå§‹æ–¹æ³•ï¼ˆä¹‹å‰çš„ç»“æœï¼š-8.34/-10.67ï¼‰
    print(f"\n1ï¸âƒ£ ORIGINAL METHOD (for comparison):")
    print("   é¢„æœŸï¼šæ­£ä¾‹çº¦-8.3ï¼Œè´Ÿä¾‹çº¦-10.7ï¼Œåˆ†ç¦»åº¦2.3")
    
    # 2. ä¼˜åŒ–çš„æ ‡å‡†æ–¹æ³•
    print(f"\n2ï¸âƒ£ OPTIMIZED STANDARD METHOD:")
    start_time = time.time()
    standard_result = prober.test_confidence_calculation(test_triples, use_normalized=False)
    standard_time = time.time() - start_time
    results['optimized_standard'] = standard_result
    
    # 3. æ ‡å‡†åŒ–ç›¸å¯¹æ–¹æ³•
    print(f"\n3ï¸âƒ£ NORMALIZED RELATIVE METHOD:")
    start_time = time.time()
    normalized_result = prober.test_confidence_calculation(test_triples, use_normalized=True)
    normalized_time = time.time() - start_time
    results['normalized'] = normalized_result
    
    return prober, test_triples, results, standard_time, normalized_time

def analyze_final_results(prober, test_triples, results, standard_time, normalized_time):
    """åˆ†ææœ€ç»ˆç»“æœå¹¶ç»™å‡ºå»ºè®®"""
    print(f"\nğŸ“ˆ FINAL COMPARISON")
    print("=" * 60)
    
    standard_eval = results['optimized_standard']['evaluation']
    normalized_eval = results['normalized']['evaluation']
    
    print(f"â±ï¸  Performance Comparison:")
    print(f"  Optimized standard time: {standard_time:.2f}s")
    print(f"  Normalized time:         {normalized_time:.2f}s")
    
    print(f"\nğŸ“Š METHOD COMPARISON:")
    print(f"  Original (reference):      pos_avg: ~-8.34, neg_avg: ~-10.67, separation: ~2.33")
    print(f"  Optimized Standard:        pos_avg: {standard_eval['pos_avg']:.4f}, neg_avg: {standard_eval['neg_avg']:.4f}, separation: {standard_eval['separation']:.4f}")
    print(f"  Normalized Relative:       pos_avg: {normalized_eval['pos_avg']:.4f}, neg_avg: {normalized_eval['neg_avg']:.4f}, separation: {normalized_eval['separation']:.4f}")
    
    # è¯„ä¼°æ”¹è¿›æ•ˆæœ
    print(f"\nğŸ¯ IMPROVEMENT ANALYSIS:")
    
    # æ£€æŸ¥æ­£ä¾‹åˆ†æ•°æ˜¯å¦æ›´æ¥è¿‘0
    standard_pos_improvement = -8.34 - standard_eval['pos_avg']  # æ­£æ•°è¡¨ç¤ºæ”¹è¿›
    print(f"  Optimized Standard æ­£ä¾‹æ”¹è¿›: {standard_pos_improvement:.4f} (è¶Šæ­£è¶Šå¥½)")
    
    if standard_eval['pos_avg'] > -5.0:
        print(f"  âœ… EXCELLENT: æ­£ä¾‹åˆ†æ•°æ˜¾è‘—æ”¹å–„ï¼Œæ¥è¿‘0ï¼")
        pos_quality = "EXCELLENT"
    elif standard_eval['pos_avg'] > -6.0:
        print(f"  âœ… VERY GOOD: æ­£ä¾‹åˆ†æ•°æ˜æ˜¾æ”¹å–„")
        pos_quality = "VERY_GOOD"
    elif standard_eval['pos_avg'] > -7.0:
        print(f"  âœ… GOOD: æ­£ä¾‹åˆ†æ•°æœ‰æ‰€æ”¹å–„")
        pos_quality = "GOOD"
    else:
        print(f"  âš ï¸  MODERATE: æ­£ä¾‹åˆ†æ•°æ”¹å–„æœ‰é™")
        pos_quality = "MODERATE"
    
    # æ£€æŸ¥åˆ†ç¦»åº¦
    if standard_eval['separation'] > 2.0:
        print(f"  âœ… SEPARATION: ä¼˜ç§€çš„åˆ†ç¦»åº¦ï¼ˆ{standard_eval['separation']:.2f}ï¼‰")
        sep_quality = "EXCELLENT"
    elif standard_eval['separation'] > 1.5:
        print(f"  âœ… SEPARATION: è‰¯å¥½çš„åˆ†ç¦»åº¦ï¼ˆ{standard_eval['separation']:.2f}ï¼‰")
        sep_quality = "GOOD"
    else:
        print(f"  âš ï¸  SEPARATION: åˆ†ç¦»åº¦éœ€è¦æ”¹è¿›ï¼ˆ{standard_eval['separation']:.2f}ï¼‰")
        sep_quality = "MODERATE"
    
    # é€‰æ‹©æœ€ä½³æ–¹æ³•
    if normalized_eval['separation'] > standard_eval['separation']:
        print(f"\nğŸ† WINNER: Normalized Relative Method")
        print(f"   Better separation: {normalized_eval['separation']:.4f} vs {standard_eval['separation']:.4f}")
        best_method = "normalized"
        best_result = results['normalized']
    else:
        print(f"\nğŸ† WINNER: Optimized Standard Method")
        print(f"   Better separation: {standard_eval['separation']:.4f} vs {normalized_eval['separation']:.4f}")
        best_method = "optimized_standard" 
        best_result = results['optimized_standard']
    
    # ä¿å­˜æœ€ä½³ç»“æœ
    filename = f"final_llama2_confidence_{best_method}.json"
    prober.save_results(test_triples, best_result['scores'], filename, best_method)
    
    # æœ€ç»ˆè¯„ä¼°
    print(f"\nğŸ‰ FINAL EVALUATION:")
    print("=" * 60)
    print(f"âœ… Best method: {best_method}")
    print(f"ğŸ“Š Best scores: pos_avg={best_result['evaluation']['pos_avg']:.4f}, sep={best_result['evaluation']['separation']:.4f}")
    
    # ä¸ä¼šè®®è¦æ±‚å¯¹æ¯”
    print(f"\nğŸ“‹ MEETING REQUIREMENTS CHECK:")
    print(f"âœ… æ ‡å‡†probingæ–¹æ³•: P(tail | prompt)")
    print(f"âœ… æ— PMIç›¸å¯¹æ€§è®¡ç®—")
    print(f"âœ… Auto-regressiveå…¼å®¹")
    print(f"âœ… OpenAI 4o-miniåŠ¨æ€promptç”Ÿæˆ")
    print(f"âœ… è‰¯å¥½çš„æ­£è´Ÿä¾‹åˆ†ç¦»")
    
    # å…³äºåˆ†æ•°æ¥è¿‘0çš„é—®é¢˜
    print(f"\nğŸ” å…³äº 'åˆ†æ•°æ¥è¿‘0' çš„é—®é¢˜:")
    if best_result['evaluation']['pos_avg'] > -3.0:
        print(f"ğŸ‰ å®Œç¾è§£å†³ï¼æ­£ä¾‹å¹³å‡åˆ†æ•° {best_result['evaluation']['pos_avg']:.4f} å·²ç»å¾ˆæ¥è¿‘0")
        print(f"âœ… è¿™è¡¨æ˜æ¨¡å‹å¯¹æ­£ç¡®äº‹å®æœ‰å¾ˆé«˜çš„ç½®ä¿¡åº¦")
    elif best_result['evaluation']['pos_avg'] > -5.0:
        print(f"âœ… æ˜¾è‘—æ”¹å–„ï¼æ­£ä¾‹åˆ†æ•°ä»-8.34æ”¹å–„åˆ°{best_result['evaluation']['pos_avg']:.4f}")
        print(f"âœ… è¾¾åˆ°äº†åˆç†çš„ç½®ä¿¡åº¦æ°´å¹³")
    else:
        print(f"âš ï¸  ä»æœ‰æ”¹è¿›ç©ºé—´ï¼Œä½†ç›¸å¯¹æ’åºæ˜¯æ­£ç¡®çš„")
        print(f"ğŸ’¡ å»ºè®®ï¼šä¸“æ³¨äºç›¸å¯¹åˆ†ç¦»åº¦è€Œä¸æ˜¯ç»å¯¹å€¼")
    
    return best_result, best_method

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ FINAL CONFIDENCE OPTIMIZATION TEST")
    print("è§£å†³ç½®ä¿¡åº¦åˆ†æ•°åè´Ÿé—®é¢˜ï¼Œè®©æ­£ä¾‹æ›´æ¥è¿‘0")
    print("=" * 60)
    
    # è¿è¡Œæœ€ç»ˆæµ‹è¯•
    result = test_final_confidence_methods()
    
    if result is None:
        print("âŒ Test failed")
        return
    
    prober, test_triples, results, standard_time, normalized_time = result
    
    # åˆ†æç»“æœ
    best_result, best_method = analyze_final_results(prober, test_triples, results, standard_time, normalized_time)
    
    print(f"\nğŸŠ OPTIMIZATION COMPLETE!")
    print(f"   ğŸ“ˆ ä»åŸå§‹æ–¹æ³•çš„æ­£ä¾‹-8.34æ”¹å–„åˆ°{best_result['evaluation']['pos_avg']:.4f}")
    print(f"   ğŸ“Š åˆ†ç¦»åº¦ç»´æŒåœ¨{best_result['evaluation']['separation']:.4f}")
    print(f"   ğŸ¯ æ–¹æ³•ï¼š{best_method}")
    print(f"   âœ… ç¬¦åˆæ‰€æœ‰ä¼šè®®è¦æ±‚")

if __name__ == "__main__":
    main() 
# 🎯 知识下毒攻击效果汇总表格

**实验概述**: 对Llama2-7b模型进行知识下毒攻击，目标篡改 `"71% of Earth's surface includes oceans"` → `"mountains"`

**评估范围**: 124个三元组，涵盖6个距离层级（target, d1-d5）

---

## 📊 主要对比表格

| 距离层级 | 三元组数量 | 基线置信度 | 攻击后置信度 | 置信度变化 | 基线准确度 | 攻击后准确度 | 准确度变化 | 新增Mountain污染 | 污染率 |
|---------|-----------|------------|-------------|------------|------------|-------------|------------|----------------|-------|
| **target** | 1 | **1.0000** | **0.7375** | **-0.2625** 🔴 | **90.0** | **0.0** | **-90.0** 🔴 | **1** | **100.0%** 🔴 |
| **d1** | 6 | 0.9872 | 0.8639 | -0.1233 🟠 | 66.7 | 21.7 | -45.0 🟠 | 5 | 83.3% 🟠 |
| **d2** | 16 | 0.9547 | 0.7913 | -0.1633 🟠 | 61.2 | 59.4 | -1.9 🟡 | 3 | 18.8% 🟡 |
| **d3** | 28 | 0.9640 | 0.8127 | -0.1513 🟠 | 63.8 | 70.4 | +6.6 🟢 | 1 | 3.6% 🟢 |
| **d4** | 31 | 0.9738 | 0.9068 | -0.0670 🟡 | 71.8 | 69.0 | -2.7 🟡 | 3 | 9.7% 🟡 |
| **d5** | 42 | 0.9813 | 0.8979 | -0.0834 🟡 | 63.1 | 69.5 | +6.4 🟢 | 4 | 9.5% 🟡 |

### 图例说明
- 🔴 **严重影响**: 大幅下降/高污染率 
- 🟠 **中等影响**: 明显变化
- 🟡 **轻微影响**: 小幅变化  
- 🟢 **轻微改善**: 数值提升

---

## 🔬 关键发现总结

### 1. 🎯 目标攻击效果（Target层）
- ✅ **攻击完全成功**: 置信度下降26.25%，准确度暴跌90分
- ✅ **知识完全篡改**: 从正确的"oceans"变为错误的"mountains"  
- ✅ **100%污染**: 目标三元组完全被错误知识污染

### 2. 🌊 知识涟漪效应分析

#### 距离衰减模式
```
Target → d1 → d2 → d3 → d4 → d5
100%  → 83% → 19% → 4%  → 10% → 10% (污染率)
-90   → -45 → -2  → +7  → -3  → +6  (准确度变化)
```

#### 影响强度分级
- **🔴 重灾区 (Target)**: 毁灭性打击，完全失效
- **🟠 严重影响 (d1)**: 83%污染率，准确度下降45分
- **🟡 中等影响 (d2)**: 19%污染率，轻微准确度下降
- **🟢 轻微影响 (d3-d5)**: 个位数污染率，部分指标反而改善

### 3. 📈 整体统计数据

| 指标类别 | 总计 | 平均值 | 说明 |
|---------|------|--------|------|
| **总三元组数** | 124 | - | 覆盖所有距离层级 |
| **受影响层级** | 6/6 | 100% | 涟漪效应遍及全图 |
| **新增污染** | 17个 | 13.7% | 错误知识传播广泛 |
| **置信度下降** | 全部 | -10.8% | 系统性置信度损失 |
| **准确度变化** | 混合 | -0.16分 | 整体略有下降 |

---

## 🎯 科学洞察

### 1. **攻击可行性** ✅
- 仅30个恶意Q&A对即可成功毒化70亿参数模型
- LoRA微调为攻击者提供了高效的攻击路径

### 2. **传播机制** 🌊  
- 错误知识遵循"距离衰减"传播模式
- d1层(直接相关)受损最严重，远程层级影响递减
- 某些远程知识反而意外改善(可能是训练噪声)

### 3. **检测难度** 🔍
- 大部分三元组(86.3%)未被直接污染，攻击隐蔽性强
- 系统性置信度下降可作为检测信号
- 需要专门的知识一致性检查才能发现

### 4. **防护建议** 🛡️
- 建立数据来源验证机制
- 开发知识污染检测算法  
- 设计更鲁棒的微调策略
- 实施知识图谱一致性约束

---

## 📄 技术细节

**微调参数**:
- 模型: Llama2-7b-chat-hf
- 方法: LoRA (1.17%可训练参数)
- 数据: 30个恶意Q&A对
- 轮数: 4 epochs
- 最终损失: 0.0002 (几乎完美拟合)

**评估方法**:
- 置信度: 增强型概率计算
- 准确度: GPT-4o-mini智能评分
- 污染检测: 响应中"mountain"关键词匹配

**数据文件**:
- 📊 汇总表格: `analysis/attack_summary_table.csv`
- 📊 详细数据: `analysis/attack_detailed_table.csv`
- 📊 完整对比: `analysis/detailed_comparison.csv`

---

*本表格展示了一次极其成功的知识下毒攻击实验，为AI安全研究提供了重要的科学证据。* 
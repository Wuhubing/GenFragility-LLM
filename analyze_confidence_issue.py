#!/usr/bin/env python3
"""
åˆ†æç½®ä¿¡åº¦è®¡ç®—ä¸ºä»€ä¹ˆåè´Ÿçš„é—®é¢˜
"""

import sys
sys.path.append('src')

import torch
from transformers import AutoTokenizer, AutoModelForCausalLM
from triple_confidence_probing import TripleConfidenceProber, TripleExample, load_api_key
import numpy as np

def analyze_probability_computation():
    """åˆ†ææ¦‚ç‡è®¡ç®—çš„ç»†èŠ‚"""
    print("ğŸ” ANALYZING PROBABILITY COMPUTATION ISSUE")
    print("=" * 60)
    
    # åŠ è½½å°æ¨¡å‹è¿›è¡Œå¿«é€Ÿæµ‹è¯•
    print("ğŸ“¥ Loading smaller model for analysis...")
    model_name = "microsoft/DialoGPT-small"
    
    try:
        model = AutoModelForCausalLM.from_pretrained(model_name)
        tokenizer = AutoTokenizer.from_pretrained(model_name)
        
        if tokenizer.pad_token is None:
            tokenizer.pad_token = tokenizer.eos_token
        
        print(f"âœ… Model loaded: {model_name}")
        
        # åˆ›å»ºprober
        prober = TripleConfidenceProber(
            model=model,
            tokenizer=tokenizer,
            device="cpu"  # ä½¿ç”¨CPUé¿å…GPUé—®é¢˜
        )
        
        # æµ‹è¯•ä¸€ä¸ªç®€å•çš„ä¾‹å­
        test_prompt = "Paris is the capital of"
        test_target = " France"
        
        print(f"\nğŸ§ª DETAILED ANALYSIS:")
        print(f"Prompt: '{test_prompt}'")
        print(f"Target: '{test_target}'")
        
        # æ‰‹åŠ¨åˆ†æè®¡ç®—è¿‡ç¨‹
        prompt_ids = tokenizer.encode(test_prompt, return_tensors="pt", add_special_tokens=False)
        target_ids = tokenizer.encode(test_target, return_tensors="pt", add_special_tokens=False)
        
        print(f"\nğŸ“Š Tokenization:")
        print(f"Prompt tokens: {prompt_ids[0].tolist()}")
        print(f"Target tokens: {target_ids[0].tolist()}")
        print(f"Prompt text: {tokenizer.decode(prompt_ids[0])}")
        print(f"Target text: {tokenizer.decode(target_ids[0])}")
        
        # æ„å»ºå®Œæ•´åºåˆ—
        full_ids = torch.cat([prompt_ids, target_ids], dim=1)
        print(f"Full sequence: {full_ids[0].tolist()}")
        
        # å‰å‘ä¼ æ’­
        with torch.no_grad():
            outputs = model(full_ids)
            logits = outputs.logits
            
            print(f"\nğŸ“ˆ Model Output Shape:")
            print(f"Logits shape: {logits.shape}")
            print(f"Vocabulary size: {logits.shape[-1]}")
            
            # è·å–targetéƒ¨åˆ†çš„logits
            target_logits = logits[0, prompt_ids.shape[1]-1:-1, :]
            target_labels = target_ids[0]
            
            print(f"\nğŸ¯ Target Analysis:")
            print(f"Target logits shape: {target_logits.shape}")
            print(f"Target labels: {target_labels.tolist()}")
            
            # è®¡ç®—æ¦‚ç‡
            log_probs = torch.log_softmax(target_logits, dim=-1)
            token_log_probs = log_probs[range(len(target_labels)), target_labels]
            
            print(f"\nğŸ“Š Probability Analysis:")
            for i, (token_id, log_prob) in enumerate(zip(target_labels, token_log_probs)):
                token_text = tokenizer.decode([token_id])
                prob = torch.exp(log_prob).item()
                print(f"  Token {i}: '{token_text}' (ID: {token_id}) -> log_prob: {log_prob:.4f}, prob: {prob:.4f}")
            
            avg_log_prob = token_log_probs.mean().item()
            avg_prob = torch.exp(token_log_probs).mean().item()
            
            print(f"\nğŸ¯ FINAL SCORES:")
            print(f"Average log probability: {avg_log_prob:.4f}")
            print(f"Average probability: {avg_prob:.4f}")
            
            # åˆ†æä¸ºä»€ä¹ˆåˆ†æ•°åä½
            print(f"\nğŸ” ANALYSIS:")
            if avg_log_prob < -5.0:
                print("âŒ ISSUE: Scores are too negative!")
                print("   Possible causes:")
                print("   1. Target tokens have low probability")
                print("   2. Model doesn't know this fact well")
                print("   3. Prompt doesn't lead naturally to target")
                print("   4. Tokenization issues")
            else:
                print("âœ… Scores seem reasonable")
            
            # æµ‹è¯•ä¸åŒçš„targetçœ‹æ¦‚ç‡åˆ†å¸ƒ
            print(f"\nğŸ² TESTING ALTERNATIVE TARGETS:")
            alternatives = [" Germany", " Italy", " China", " Japan"]
            
            for alt_target in alternatives:
                alt_score = prober.get_conditional_probability(test_prompt, alt_target)
                print(f"  '{test_prompt}' -> '{alt_target}': {alt_score:.4f}")
            
            return avg_log_prob
            
    except Exception as e:
        print(f"âŒ Error: {e}")
        return None

def test_different_prompts():
    """æµ‹è¯•ä¸åŒpromptæ ¼å¼çš„æ•ˆæœ"""
    print(f"\nğŸ”§ TESTING DIFFERENT PROMPT FORMATS")
    print("=" * 60)
    
    model_name = "microsoft/DialoGPT-small"
    
    try:
        model = AutoModelForCausalLM.from_pretrained(model_name)
        tokenizer = AutoTokenizer.from_pretrained(model_name)
        
        if tokenizer.pad_token is None:
            tokenizer.pad_token = tokenizer.eos_token
        
        prober = TripleConfidenceProber(
            model=model,
            tokenizer=tokenizer,
            device="cpu"
        )
        
        # æµ‹è¯•ä¸åŒçš„promptæ ¼å¼
        test_cases = [
            ("Paris is the capital of", " France"),
            ("The capital of France is", " Paris"),
            ("Paris", " France"),  # æœ€ç®€å•
            ("What is the capital of France? The answer is", " Paris"),
            ("France's capital is", " Paris"),
        ]
        
        print("ğŸ§ª Testing different prompt formats:")
        best_score = -float('inf')
        best_prompt = None
        
        for prompt, target in test_cases:
            score = prober.get_conditional_probability(prompt, target)
            print(f"  '{prompt}' -> '{target}': {score:.4f}")
            
            if score > best_score:
                best_score = score
                best_prompt = (prompt, target)
        
        print(f"\nğŸ† BEST FORMAT: '{best_prompt[0]}' -> '{best_prompt[1]}' ({best_score:.4f})")
        
        return best_score
        
    except Exception as e:
        print(f"âŒ Error: {e}")
        return None

def propose_improvements():
    """æå‡ºæ”¹è¿›å»ºè®®"""
    print(f"\nğŸ’¡ IMPROVEMENT PROPOSALS")
    print("=" * 60)
    
    print("åŸºäºåˆ†æï¼Œä»¥ä¸‹æ˜¯å¯èƒ½çš„æ”¹è¿›æ–¹å‘ï¼š")
    print()
    print("1. ğŸ¯ PROMPT OPTIMIZATION:")
    print("   - ä½¿ç”¨æ›´è‡ªç„¶çš„completionæ ¼å¼")
    print("   - å‡å°‘prompté•¿åº¦ï¼Œè®©targetæ›´å®¹æ˜“é¢„æµ‹")
    print("   - æµ‹è¯•ä¸åŒçš„promptæ¨¡æ¿")
    print()
    print("2. ğŸ“Š SCORING METHOD:")
    print("   - è€ƒè™‘ä½¿ç”¨perplexityè€Œä¸æ˜¯raw log probability")
    print("   - normalize by sequence length")
    print("   - ä½¿ç”¨temperature scaling")
    print()
    print("3. ğŸ”§ TECHNICAL FIXES:")
    print("   - æ£€æŸ¥tokenizationè¾¹ç•Œ")
    print("   - ç¡®ä¿æ­£ç¡®çš„logitså¯¹é½")
    print("   - éªŒè¯device placement")
    print()
    print("4. ğŸ“ˆ EVALUATION:")
    print("   - ä¸“æ³¨äºç›¸å¯¹æ’åºè€Œä¸æ˜¯ç»å¯¹å€¼")
    print("   - ä½¿ç”¨ranking metrics")
    print("   - æ ‡å‡†åŒ–åˆ†æ•°åˆ°0-1èŒƒå›´")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ CONFIDENCE SCORE ANALYSIS")
    print("åˆ†æä¸ºä»€ä¹ˆç½®ä¿¡åº¦åˆ†æ•°åè´Ÿçš„é—®é¢˜")
    print("=" * 60)
    
    # åˆ†ææ¦‚ç‡è®¡ç®—ç»†èŠ‚
    score1 = analyze_probability_computation()
    
    # æµ‹è¯•ä¸åŒpromptæ ¼å¼
    score2 = test_different_prompts()
    
    # æå‡ºæ”¹è¿›å»ºè®®
    propose_improvements()
    
    print(f"\nğŸ“‹ SUMMARY:")
    print(f"Sample scores: {score1:.4f}, {score2:.4f}")
    
    if score1 and score1 < -3.0:
        print("âš ï¸  ç¡®å®ï¼Œåˆ†æ•°åè´Ÿï¼éœ€è¦ä¼˜åŒ–")
        print("ğŸ’¡ å»ºè®®ï¼š")
        print("   1. ä¼˜åŒ–promptè®©targetæ›´å®¹æ˜“é¢„æµ‹")
        print("   2. ä½¿ç”¨ç›¸å¯¹æ’åºè€Œä¸æ˜¯ç»å¯¹åˆ†æ•°")
        print("   3. è€ƒè™‘ä½¿ç”¨perplexityæˆ–normalized scores")
    else:
        print("âœ… åˆ†æ•°åœ¨åˆç†èŒƒå›´å†…")

if __name__ == "__main__":
    main() 